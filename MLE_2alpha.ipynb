{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Zeyun Wu\n",
    "# Date: July 8th 2019\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ToyQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py:1700: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('UH_RL_rats.csv')\n",
    "df = df.drop(df.columns[[range(24)]],axis=1)\n",
    "subjects = df['subject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>subject</th>\n",
       "      <th>lever</th>\n",
       "      <th>response</th>\n",
       "      <th>feedback</th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>alpha_gain</th>\n",
       "      <th>alpha_loss</th>\n",
       "      <th>beta</th>\n",
       "      <th>Q</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>rich</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>rich</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>lean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>rich</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.259718</td>\n",
       "      <td>0.860397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>lean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  session  subject lever response  feedback  state  action  reward  \\\n",
       "0       1       10     A     rich       0.0    1.0     1.0     0.0   \n",
       "1       1       10     A     rich       1.0    1.0     1.0     1.0   \n",
       "2       1       10     B     lean       0.0    1.0     2.0     0.0   \n",
       "3       1       10     A     rich       1.0    1.0     1.0     1.0   \n",
       "4       1       10     B     lean       0.0    1.0     2.0     0.0   \n",
       "\n",
       "   alpha_gain  alpha_loss  beta         Q        PE  \n",
       "0    0.139603         1.0  20.0  0.000000 -0.500000  \n",
       "1    0.139603         1.0  20.0  0.139603  1.000000  \n",
       "2    0.139603         1.0  20.0  0.000000 -0.500000  \n",
       "3    0.139603         1.0  20.0  0.259718  0.860397  \n",
       "4    0.139603         1.0  20.0  0.000000  0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide df into 5 dfs according to session\n",
    "# '1,11,16,6,Best'\n",
    "session = df['session'].unique()\n",
    "df_1 = df[df['session']=='1']\n",
    "df_11 = df[df['session']=='11']\n",
    "df_16 = df[df['session']=='16']\n",
    "df_6 = df[df['session']=='6']\n",
    "df_best = df[df['session']=='Best']\n",
    "df_list = [df_1,df_11,df_16,df_6,df_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# action list, reward list, and Q list\n",
    "action_list = []\n",
    "reward_list = []\n",
    "Q_list = []\n",
    "\n",
    "# the k-th array in each list corresponds to (1+k%20)-th object in session[int(k/5)]\n",
    "for i in range(len(session)):\n",
    "    for j in range(len(subjects)):\n",
    "        subj = j + 1 # subjects 1-20\n",
    "        df_sess = df_list[i]\n",
    "        action = np.array(df_sess['action'][df_sess['subject']==subj])\n",
    "        reward = np.array(df_sess['reward'][df_sess['subject']==subj])\n",
    "        Q = np.array(df_sess['Q'][df_sess['subject']==subj])\n",
    "                \n",
    "        action_list.append(action)\n",
    "        reward_list.append(reward)\n",
    "        Q_list.append(Q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Q_list[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reward_list[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action_list[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15177b43c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Q_list[10]) #weird\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# demo\n",
    "env=toyQ_2choice()\n",
    "rat=sig_rat(env,alpha=0.2,beta=2)\n",
    "env,rat=train_rat(env,rat,300)\n",
    "obslog=np.array(env.obslog)\n",
    "choicelog=np.array(rat.choiceLog) \n",
    "print('reward_log:',np.sum(obslog,axis=0))\n",
    "print('choice_log:',np.sum(choicelog,axis=0))\n",
    "rat.Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance between Q and Q_MLE\n",
    "\n",
    "rats with single Q and two alphas for win and lose respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameter: action, a list of numpy arrays of action data; reward, a list of np array of reward data\n",
    "# beta, sharpness of sigmoid; alpha, learning rate; Qleft, if the Q is describing the quality for the left\n",
    "# return the sum of log-likelihood\n",
    "###!!! suppose the reward stands for the objective reward\n",
    "def neg_log_likelihood_sigQ(alpha,beta,actions,rewards,Q=0,gamma=0,Qleft=True): \n",
    "    n = len(actions)\n",
    "    sum_ll = 0\n",
    "    for i in range(n):\n",
    "        turn = actions[i]\n",
    "        rew = rewards[i]\n",
    "        if turn == 1:\n",
    "            Q = Q + alpha*(rew - Q + gamma*np.max(Q))\n",
    "        else:\n",
    "            Q = Q - alpha*(rew - Q + gamma*np.max(Q))\n",
    "\n",
    "        if np.array_equal(turn,np.array([1,0])):\n",
    "            prob = 1/(np.exp(0-beta*Q)+1)\n",
    "        else:\n",
    "            prob = 1 - 1/(np.exp(0-beta*Q)+1)\n",
    "        \n",
    "        sum_ll = sum_ll - np.log(prob + np.exp(0-8)) # add a smoother to avoid warnings\n",
    "    \n",
    "    return sum_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neg_log_likelihood_sigQ_2alpha(alphaG,alphaL,beta,actions,rewards,Q=0,gamma=0,Qleft=True): \n",
    "    n = len(actions)\n",
    "    sum_ll = 0\n",
    "    for i in range(n):\n",
    "        turn = actions[i]\n",
    "        rew = rewards[i]\n",
    "        \n",
    "        if int(turn) == 2 & int(rew) == 1:\n",
    "            rew = 0\n",
    "            Q = Q + alphaG*(rew - Q + gamma*np.max(Q))\n",
    "        elif int(turn) == 2 & int(rew) == 0:\n",
    "            rew = 1\n",
    "            Q = Q + alphaL*(rew - Q + gamma*np.max(Q))\n",
    "        elif int(turn) == 1 & int(rew) == 1:\n",
    "            rew = 1\n",
    "            Q = Q - alphaG*(rew - Q + gamma*np.max(Q))\n",
    "        else:\n",
    "            rew = 0\n",
    "            Q = Q + alphaL*(rew - Q + gamma*np.max(Q))\n",
    "        \n",
    "        if np.array_equal(turn,np.array([1,0])):\n",
    "            prob = 1/(np.exp(0-beta*Q)+1)\n",
    "        else:\n",
    "            prob = 1 - 1/(np.exp(0-beta*Q)+1)\n",
    "        \n",
    "        sum_ll = sum_ll - np.log(prob + np.exp(0-8)) # add a smoother to avoid warnings\n",
    "    \n",
    "    return sum_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params = [alphaG0,alphaL0,beta0]\n",
    "# args = [actions,rewards]\n",
    "def helper_func_2alpha(params,args):\n",
    "    alphaG0 = params[0]\n",
    "    alphaL0 = params[1]\n",
    "    beta0 = params[2]\n",
    "    actions = args[0]\n",
    "    rewards = args[1]\n",
    "    \n",
    "    sum_ll = neg_log_likelihood_sigQ_2alpha(alphaG0,alphaL0,beta0,actions,rewards)\n",
    "    \n",
    "    return sum_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that estimates the maximum-likelihood beta_hat numerically\n",
    "# parameters: actions, a numpy array recording action of agent in each turn; beta is the parameter in density func\n",
    "# return minimization summary and print beta_hat\n",
    "def MLE_2alpha(actions,rewards,alphaG0,alphaL0,beta0):\n",
    "    initial_guess = [alphaG0,alphaL0,beta0]\n",
    "    args = [actions,rewards]\n",
    "    bounds = ((0,1),(0,1),(0,10*beta0))\n",
    "    result = minimize(helper_func_2alpha,initial_guess,args=args,bounds = bounds)\n",
    "    if(result.success):\n",
    "        #print(result.message)\n",
    "        #print('The MLE for beta is', result.x)\n",
    "        #print('Iteration =', result.nit)\n",
    "        a=0\n",
    "    else:\n",
    "        print('The optimization did not converge, beta0 equals', beta0,', and alphaG0 equals',alphaG0)\n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return mse between simulated Q and Q_hat calculated with optimal beta from MLE\n",
    "def Q_distance_2alpha(iteration,alphaG0,alphaL0,beta0):\n",
    "    env = ToyQ2.toyQ_2choice()\n",
    "    rat = ToyQ2.SQFSrat(env, alphaF=alphaL0,alphaS=alphaG0, beta=beta0)\n",
    "    env,rat = ToyQ2.train_rat(env,rat,iteration)\n",
    "    \n",
    "    Q = np.array(rat.Qlog)\n",
    "    actions = rat.choiceLog\n",
    "    rewards = env.obslog\n",
    "    \n",
    "    result = MLE_2alpha(actions,rewards,alphaG0,alphaL0,beta0)\n",
    "    alphaG_hat = result.x[0]\n",
    "    alphaL_hat = result.x[1]\n",
    "    beta_hat = result.x[2]\n",
    "    \n",
    "    rat_hat = ToyQ2.SQFSrat(env,alphaF=alphaL_hat,alphaS=alphaG_hat, beta=beta_hat)\n",
    "    env,rat_hat = ToyQ2.train_rat(env,rat_hat,iteration)\n",
    "    Q_hat = np.array(rat_hat.Qlog)\n",
    "    \n",
    "    #Q[0]=[0,0] does not matter\n",
    "    mse = np.linalg.norm(Q-Q_hat)**2/iteration \n",
    "    #axis=None perform mean elementwise   (np.square(Q-Q_hat)).mean(axis=None)*2\n",
    "    \n",
    "    return mse\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization did not converge, beta0 equals 2 , and alphaG0 equals 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0625702674099439"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "Q_distance_2alpha(300,0.2,0.2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MLE on real data\n",
    "\n",
    "Suppose actions and rewards are exactly same as the real experiment, use the alphas and beta in the dataset and calculate the mean squared error between Q in dataset and MLE Q\n",
    "\n",
    "Also suppose the action function is sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py:1700: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('UH_RL_rats.csv')\n",
    "df = df.drop(df.columns[[range(24)]],axis=1)\n",
    "subjects = df['subject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide df into 5 dfs according to session\n",
    "# '1,11,16,6,Best'\n",
    "session = df['session'].unique()\n",
    "df_1 = df[df['session']=='1']\n",
    "df_11 = df[df['session']=='11']\n",
    "df_16 = df[df['session']=='16']\n",
    "df_6 = df[df['session']=='6']\n",
    "df_best = df[df['session']=='Best']\n",
    "df_list = [df_1,df_11,df_16,df_6,df_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# action list, reward list, and Q list\n",
    "action_list = []\n",
    "reward_list = []\n",
    "Q_list = []\n",
    "alphaG_list = []\n",
    "alphaL_list = []\n",
    "beta_list = []\n",
    "\n",
    "# the k-th array in each list corresponds to (1+k%20)-th object in session[int(k/5)]\n",
    "for i in range(len(session)):\n",
    "    for j in range(len(subjects)):\n",
    "        subj = j + 1 # subjects 1-20\n",
    "        df_sess = df_list[i]\n",
    "        action = np.array(df_sess['action'][df_sess['subject']==subj])\n",
    "        reward = np.array(df_sess['reward'][df_sess['subject']==subj])\n",
    "        Q = np.array(df_sess['Q'][df_sess['subject']==subj])\n",
    "        alphaG = np.unique(df_sess['alpha_gain'][df_sess['subject']==subj])\n",
    "        alphaL = np.unique(df_sess['alpha_loss'][df_sess['subject']==subj])\n",
    "        beta = np.unique(df_sess['beta'][df_sess['subject']==subj])\n",
    "                \n",
    "        action_list.append(action)\n",
    "        reward_list.append(reward)\n",
    "        Q_list.append(Q)\n",
    "        alphaG_list.append(alphaG)\n",
    "        alphaL_list.append(alphaL)\n",
    "        beta_list.append(beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>subject</th>\n",
       "      <th>lever</th>\n",
       "      <th>response</th>\n",
       "      <th>feedback</th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>alpha_gain</th>\n",
       "      <th>alpha_loss</th>\n",
       "      <th>beta</th>\n",
       "      <th>Q</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>rich</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>rich</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>lean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>rich</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.259718</td>\n",
       "      <td>0.860397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>lean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  session  subject lever response  feedback  state  action  reward  \\\n",
       "0       1       10     A     rich       0.0    1.0     1.0     0.0   \n",
       "1       1       10     A     rich       1.0    1.0     1.0     1.0   \n",
       "2       1       10     B     lean       0.0    1.0     2.0     0.0   \n",
       "3       1       10     A     rich       1.0    1.0     1.0     1.0   \n",
       "4       1       10     B     lean       0.0    1.0     2.0     0.0   \n",
       "\n",
       "   alpha_gain  alpha_loss  beta         Q        PE  \n",
       "0    0.139603         1.0  20.0  0.000000 -0.500000  \n",
       "1    0.139603         1.0  20.0  0.139603  1.000000  \n",
       "2    0.139603         1.0  20.0  0.000000 -0.500000  \n",
       "3    0.139603         1.0  20.0  0.259718  0.860397  \n",
       "4    0.139603         1.0  20.0  0.000000  0.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate mean square error between Qlog and Q_hat\n",
    "#return both mle result and mse\n",
    "def simple_Q_distance(alphaG0,alphaL0,beta0,actions,rewards,Qlog):\n",
    "    iteration = len(Qlog)\n",
    "    \n",
    "    MLE_result = MLE_2alpha(actions,rewards,alphaG0,alphaL0,beta0)\n",
    "    alphaG_hat = MLE_result.x[0]\n",
    "    alphaL_hat = MLE_result.x[1]\n",
    "    beta_hat = MLE_result.x[2]\n",
    "    \n",
    "    #get Q_hat from simulation\n",
    "    env = ToyQ2.toyQ_2choice()\n",
    "    rat_hat = ToyQ2.SQFSrat(env,alphaF=alphaL_hat,alphaS=alphaG_hat, beta=beta_hat)\n",
    "    env,rat_hat = ToyQ2.train_rat(env,rat_hat,iteration)\n",
    "    Q_hat = np.array(rat_hat.Qlog)\n",
    "    \n",
    "    Q_hat = Q_hat[:-1] # the last Q was not used in deciding the rat's action\n",
    "    \n",
    "    \n",
    "    mse = np.linalg.norm(Qlog-Q_hat)**2/iteration \n",
    "    return MLE_result,mse\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "#demo\n",
    "mle,mse = simple_Q_distance(0.139603,1.0,20.0,action_list[0],reward_list[0],Q_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 5.444891942680578\n",
       " hess_inv: array([[4379.13193247, -623.48758303, 2935.33681887],\n",
       "       [-623.48758303,   89.05639837, -418.25534566],\n",
       "       [2935.33681887, -418.25534566, 1968.95802283]])\n",
       "      jac: array([-2.02655792e-06,  5.06639481e-06,  0.00000000e+00])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 110\n",
       "      nit: 20\n",
       "     njev: 22\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([8.89337750e-01, 3.17758577e-03, 2.02592918e+01])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in double_scalars\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:160: RuntimeWarning: overflow encountered in double_scalars\n",
      "  self.Q=(1-self.alphaF)*self.Q # going left and not getting an reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization did not converge, beta0 equals 0.0116936679912 , and alphaG0 equals 0.0006500555444439999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in double_scalars\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:160: RuntimeWarning: overflow encountered in double_scalars\n",
      "  self.Q=(1-self.alphaF)*self.Q # going left and not getting an reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization did not converge, beta0 equals 0.000711877618334 , and alphaG0 equals 3.00272320299e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  val = 1/(1+np.exp(0-beta*q))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization did not converge, beta0 equals 0.726263703524 , and alphaG0 equals 0.18582544577799998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization did not converge, beta0 equals 0.536254523587 , and alphaG0 equals 0.545370052041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization did not converge, beta0 equals 0.5888181635549999 , and alphaG0 equals 0.14170465664100002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization did not converge, beta0 equals 0.347512382615 , and alphaG0 equals 0.11709156960999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in double_scalars\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:160: RuntimeWarning: overflow encountered in double_scalars\n",
      "  self.Q=(1-self.alphaF)*self.Q # going left and not getting an reward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization did not converge, beta0 equals 0.154716349968 , and alphaG0 equals 0.261299314818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n",
      "/Users/erika/Lab/m/MLE_simulated/ToyQ2.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  val = 1/(1+np.exp(0-beta*q))\n",
      "/Users/erika/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization did not converge, beta0 equals 0.378301326316 , and alphaG0 equals 0.681418991388\n"
     ]
    }
   ],
   "source": [
    "# check if all alphas and beta are MLE result\n",
    "truth_list = []\n",
    "mse_list = []\n",
    "for i in range(len(alphaG_list)):\n",
    "    mle,mse = simple_Q_distance(alphaG_list[i][0],alphaL_list[i][0],beta_list[i][0],action_list[i],reward_list[i],\n",
    "                                Q_list[i])\n",
    "    val = abs(mle.x[0] - alphaG_list[i][0])/mle.x[0] < 0.1\n",
    "    val = val and abs(mle.x[1] - alphaL_list[i][0])/mle.x[1] < 0.1\n",
    "    val = val and abs(mle.x[2] - beta_list[i][0])/mle.x[2] <0.2\n",
    "    \n",
    "    truth_list.append(val)\n",
    "    mse_list.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>subject</th>\n",
       "      <th>lever</th>\n",
       "      <th>response</th>\n",
       "      <th>feedback</th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>alpha_gain</th>\n",
       "      <th>alpha_loss</th>\n",
       "      <th>beta</th>\n",
       "      <th>Q</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>rich</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>rich</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>lean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>rich</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.259718</td>\n",
       "      <td>0.860397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>lean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  session  subject lever response  feedback  state  action  reward  \\\n",
       "0       1       10     A     rich       0.0    1.0     1.0     0.0   \n",
       "1       1       10     A     rich       1.0    1.0     1.0     1.0   \n",
       "2       1       10     B     lean       0.0    1.0     2.0     0.0   \n",
       "3       1       10     A     rich       1.0    1.0     1.0     1.0   \n",
       "4       1       10     B     lean       0.0    1.0     2.0     0.0   \n",
       "\n",
       "   alpha_gain  alpha_loss  beta         Q        PE  \n",
       "0    0.139603         1.0  20.0  0.000000 -0.500000  \n",
       "1    0.139603         1.0  20.0  0.139603  1.000000  \n",
       "2    0.139603         1.0  20.0  0.000000 -0.500000  \n",
       "3    0.139603         1.0  20.0  0.259718  0.860397  \n",
       "4    0.139603         1.0  20.0  0.000000  0.000000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated rats with 2 alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temp\n",
    "def neg_log_likelihood_sigQ_2alpha(alphaG,alphaL,beta,actions,rewards,Q=0,gamma=0,Qleft=True): \n",
    "    n = len(actions)\n",
    "    sum_ll = 0\n",
    "    for i in range(n):\n",
    "        turn = actions[i]\n",
    "        rew = rewards[i]\n",
    "        \n",
    "        if (turn == np.array([0,1])).all() & (rew == np.array([0,1])).all():\n",
    "            rew = 0\n",
    "            Q = Q + alphaG*(rew - Q + gamma*np.max(Q))\n",
    "        elif (turn == np.array([0,1])).all() & (rew == np.array([1,0])).all():\n",
    "            rew = 1\n",
    "            Q = Q + alphaL*(rew - Q + gamma*np.max(Q))\n",
    "        elif (turn == np.array([1,0])).all() & (rew == np.array([1,0])).all():\n",
    "            rew = 1\n",
    "            Q = Q - alphaG*(rew - Q + gamma*np.max(Q))\n",
    "        else:\n",
    "            rew = 0\n",
    "            Q = Q + alphaL*(rew - Q + gamma*np.max(Q))\n",
    "\n",
    "        \n",
    "        if np.array_equal(turn,np.array([1,0])):\n",
    "            prob = 1/(np.exp(0-beta*Q)+1)\n",
    "        else:\n",
    "            prob = 1 - 1/(np.exp(0-beta*Q)+1)\n",
    "        \n",
    "        sum_ll = sum_ll - np.log(prob + np.exp(0-8)) # add a smoother to avoid warnings\n",
    "    \n",
    "    return sum_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = ToyQ2.toyQ_2choice()\n",
    "rat = ToyQ2.SQFSrat(env,alphaF=0.3,alphaS=0.2, beta=4)\n",
    "env,rat = ToyQ2.train_rat(env,rat,100)\n",
    "Q = np.array(rat_hat.Qlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = rat.choiceLog\n",
    "rewards = env.obslog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 69.24764802738692\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([1.89004652, 0.        , 0.        ])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 8\n",
       "      nit: 1\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.        , 1.        , 0.34387535])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLE_2alpha(actions,rewards,0.2,0.4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.2977602818634"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_log_likelihood_sigQ_2alpha(0.2,0.4,4,actions,rewards,Q=0,gamma=0,Qleft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.24764802738692"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper_func_2alpha(params=(0,2,0,4,4),args=(actions,rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
