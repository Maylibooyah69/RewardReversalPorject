{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.io as sio\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Note\n",
    "\n",
    "### purpose of this file is to get parameters (alphaG, alphaL, beta) of Q learning for real behavioral data\n",
    "\n",
    "### reward in this file is always subjective reward, i.e. 0 <==> the rat did not get reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1 = pd.read_csv('Data/Day 1.csvQ_Analysis.csv')\n",
    "day21 = pd.read_csv('Data/Day 21.csvQ_Analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'subject', 'prog', 'target_lat', 'non_target_lat', 'ITI',\n",
       "       'ISI', 'Tone', 'TargetOutcome', 'NonTargetOutcome', 'NAN', 'TargetSide',\n",
       "       'Omission', 'TimeOut', 'SessionTime', 'NAN.1', 'NAN.2',\n",
       "       'SwitchContingency', 'trial', 'position'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let rat 30 be chosen\n",
    "# low tone <==> reward\n",
    "day1_30 = day1[day1['subject']==30]\n",
    "day21_30 = day21[day21['subject']==30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_30 = day1_30[['Tone','TargetOutcome','NonTargetOutcome','TargetSide']]\n",
    "day21_30 = day21_30[['Tone','TargetOutcome','NonTargetOutcome','TargetSide']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tone</th>\n",
       "      <th>TargetOutcome</th>\n",
       "      <th>NonTargetOutcome</th>\n",
       "      <th>TargetSide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tone  TargetOutcome  NonTargetOutcome  TargetSide\n",
       "291  2000.0            1.0               0.0         1.0\n",
       "292  5000.0            0.0              -1.0         1.0\n",
       "293  5000.0            0.0              -1.0         1.0\n",
       "294  2000.0            0.0               1.0         1.0\n",
       "295  5000.0           -1.0               0.0         1.0\n",
       "296  5000.0            0.0              -1.0         1.0\n",
       "297  2000.0            0.0               1.0         1.0\n",
       "298  5000.0            0.0              -1.0         1.0\n",
       "299  5000.0            0.0              -1.0         1.0\n",
       "300  5000.0            0.0              -1.0         1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1_30[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Actions and Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df: 4 columns of 'Tone','TargetOutcome','NonTargetOutcome','TargetSide'; df is for one rat in one session\n",
    "# consisting of 1(left) and 2(right)\n",
    "# suppose TargetSide=1.0 means left, 4.0 means right\n",
    "def get_action(df):\n",
    "    actions = []\n",
    "    targetSide = df['TargetSide'].tolist()\n",
    "    targetOut = df['TargetOutcome'].tolist()\n",
    "    for i in range(df.shape[0]):\n",
    "        act = -1\n",
    "        if(targetSide[i]==1.0):\n",
    "            if(targetOut[i]==0):\n",
    "                act = 2\n",
    "            else:\n",
    "                act = 1\n",
    "        else:\n",
    "            if(targetOut[i]==0):\n",
    "                act = 1\n",
    "            else:\n",
    "                act = 2\n",
    "        actions.append(act)\n",
    "        \n",
    "    return actions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df: 4 columns of 'Tone','TargetOutcome','NonTargetOutcome','TargetSide'; df is for one rat in one session\n",
    "# reward is subjective, depending on whether the rat got reward\n",
    "def get_reward(df):\n",
    "    rewards = []\n",
    "    targetOut = df['TargetOutcome'].tolist()\n",
    "    nontargetOut = df['NonTargetOutcome'].tolist()\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        rew = -1\n",
    "        if(targetOut[i] == 1 or nontargetOut[i] == 1):\n",
    "            rew = 1\n",
    "        else:\n",
    "            rew = 0\n",
    "        rewards.append(rew)\n",
    "        \n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action is from choice_Log consisting of 1 and 2s\n",
    "# reward is subjective, depending on whether the rat got reward\n",
    "def neg_log_likelihood_2Q_2alpha(alphaG,alphaL,beta,actions,rewards,Q=[0.1,0.1],gamma=0,Qleft=True): \n",
    "    n = len(actions)\n",
    "    sum_ll = 0\n",
    "    for i in range(n):\n",
    "        turn = int(actions[i] - 1)\n",
    "        rew = int(rewards[i])\n",
    "        \n",
    "        if int(rew) == 1: # alpha_gain\n",
    "            Q[turn] = Q[turn] + alphaG*(rew - Q[turn] + gamma*np.max(Q))\n",
    "        elif int(rew) == 0: # alpha_loss\n",
    "            Q[turn] = Q[turn] + alphaL*(rew - Q[turn] + gamma*np.max(Q))\n",
    "        \n",
    "        temp = 1/(np.exp(0-beta*(Q[0])) + 1)\n",
    "        \n",
    "        if int(turn) == 0:\n",
    "            prob = temp\n",
    "        else:\n",
    "            prob = 1 - temp\n",
    "        \n",
    "        sum_ll = sum_ll - np.log(prob + np.exp(0-8)) # add a smoother to avoid warnings\n",
    "    \n",
    "    return sum_ll/50 #rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = [alphaG0,alphaL0,beta0]\n",
    "# args = [actions,rewards]\n",
    "def helper_func_2alpha(params,args):\n",
    "    alphaG0 = params[0]\n",
    "    alphaL0 = params[1]\n",
    "    beta0 = params[2]\n",
    "    actions = args[0]\n",
    "    rewards = args[1]\n",
    "    \n",
    "    sum_ll = neg_log_likelihood_2Q_2alpha(alphaG0,alphaL0,beta0,actions,rewards)\n",
    "    \n",
    "    return sum_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that estimates the maximum-likelihood beta_hat numerically\n",
    "# parameters: actions, a numpy array recording action of agent in each turn; beta is the parameter in density func\n",
    "# return minimization summary and print beta_hat\n",
    "def MLE_2alpha(actions,rewards,alphaG0,alphaL0,beta0):\n",
    "    initial_guess = [alphaG0,alphaL0,beta0]\n",
    "    args = [actions,rewards]\n",
    "    bounds = ((0,1),(0,1),(0,20))\n",
    "    result = minimize(helper_func_2alpha,initial_guess,args=args,bounds = bounds)\n",
    "    if(result.success):\n",
    "        #print(result.message)\n",
    "        #print('The MLE for beta is', result.x)\n",
    "        #print('Iteration =', result.nit)\n",
    "        a=0\n",
    "    else:\n",
    "        print('The optimization did not converge, beta0 equals', beta0,', and alphaG0 equals',alphaG0)\n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_minimize(actions,rewards, alphaG=0, alphaL=0, beta=0):\n",
    "    likelihoods = []\n",
    "    #step = 1/10  #1/int(iteration**(1/3))\n",
    "    alphaG_arr = np.arange(0,1,0.05)\n",
    "    alphaL_arr = np.arange(0,1,0.05)\n",
    "    beta_arr = np.arange(0,20,0.5)\n",
    "    num_G = len(alphaG_arr)\n",
    "    num_L = len(alphaL_arr)\n",
    "    num_b = len(beta_arr)\n",
    "    \n",
    "    index_G = 0\n",
    "    index_L = 0\n",
    "    index_b = 0\n",
    "    \n",
    "    temp = 100000\n",
    "    \n",
    "    for i in range(num_G):\n",
    "        for j in range(num_L):\n",
    "            for k in range(num_b):\n",
    "                \n",
    "                ll = neg_log_likelihood_2Q_2alpha(alphaG_arr[i],alphaL_arr[j],beta_arr[k],actions,rewards)\n",
    "                likelihoods.append(ll)\n",
    "                \n",
    "                if(ll < temp):\n",
    "                    temp = ll\n",
    "                    index_G = i\n",
    "                    index_L = j\n",
    "                    index_b = k\n",
    "    \n",
    "    alphaG_ = alphaG_arr[index_G]\n",
    "    alphaL_ = alphaL_arr[index_L]\n",
    "    beta_ = beta_arr[index_b]\n",
    "    \n",
    "    return [alphaG_,alphaL_,beta_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_MLE(actions,rewards, alphaG=0, alphaL=0, beta=0):\n",
    "    likelihoods = []\n",
    "    #step = 1/10  #1/int(iteration**(1/3))\n",
    "    alphaG_arr = np.arange(0,1,0.05)\n",
    "    alphaL_arr = np.arange(0,1,0.05)\n",
    "    beta_arr = np.arange(0,20,0.5)\n",
    "    num_G = len(alphaG_arr)\n",
    "    num_L = len(alphaL_arr)\n",
    "    num_b = len(beta_arr)\n",
    "    \n",
    "    index_G = 0\n",
    "    index_L = 0\n",
    "    index_b = 0\n",
    "    \n",
    "    temp = 100000\n",
    "    \n",
    "    for i in range(num_G):\n",
    "        for j in range(num_L):\n",
    "            for k in range(num_b):\n",
    "                \n",
    "                ll = neg_log_likelihood_2Q_2alpha(alphaG_arr[i],alphaL_arr[j],beta_arr[k],actions,rewards)\n",
    "                likelihoods.append(ll)\n",
    "                \n",
    "                if(ll < temp):\n",
    "                    temp = ll\n",
    "                    index_G = i\n",
    "                    index_L = j\n",
    "                    index_b = k\n",
    "    \n",
    "    alphaG_ = alphaG_arr[index_G]\n",
    "    alphaL_ = alphaL_arr[index_L]\n",
    "    beta_ = beta_arr[index_b]\n",
    "    \n",
    "    return [alphaG_,alphaL_,beta_]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
